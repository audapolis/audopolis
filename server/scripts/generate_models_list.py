from collections import defaultdict
from pathlib import Path

import huggingface_hub
import requests
import yaml
from bs4 import BeautifulSoup

WHISPER_MODELS = {
    "tiny": "guillaumekln/faster-whisper-tiny",
    "base": "guillaumekln/faster-whisper-base",
    "small": "guillaumekln/faster-whisper-small",
    "medium": "guillaumekln/faster-whisper-medium",
    "large-v1": "guillaumekln/faster-whisper-large-v1",
    "large-v2": "guillaumekln/faster-whisper-large-v2",
    "tiny.en": "guillaumekln/faster-whisper-tiny.en",
    "base.en": "guillaumekln/faster-whisper-base.en",
    "small.en": "guillaumekln/faster-whisper-small.en",
    "medium.en": "guillaumekln/faster-whisper-medium.en",
}

HARDCODED_MODELS = []

models = []

api = huggingface_hub.HfApi()
for name, url in WHISPER_MODELS.items():
    repo_info = api.repo_info(url, files_metadata=True)
    models.append(
        {
            "lang": "English" if name.endswith(".en") else "Universal",
            "name": f"whisper-{name}",
            "url": url,
            "description": "Whisper model doing both transcription and punctuation reconstruction",
            "size": f"{int(sum(f.size for f in repo_info.siblings) / 1024 / 1024)}M",
            "type": "whisper",
            "download_type": "huggingface",
        },
    )

models.extend(HARDCODED_MODELS)

r = requests.get("https://alphacephei.com/vosk/models")
assert r.status_code == 200
soup = BeautifulSoup(r.content, "html.parser")
table = soup.find("table")

columns = [x.text for x in table.find_all("th")]
rows = table.find("tbody").find_all("tr")
current_lang = None
for row in rows:
    if strong := row.find("strong"):
        current_lang = strong.text
    else:
        assert (
            current_lang is not None
        ), "no previous language heading found, probably the format changed :("
        raw = {k: v for k, v in zip(columns, row.find_all("td"))}

        current_lang = current_lang.replace("Other", "").strip()

        if current_lang == "Speaker identification model":
            continue

        name = "big"
        possible_names = ["small", "nano", "zamia", "linto-2.0", "linto-2.2", "lgraph"]
        for possible_name in possible_names:
            if possible_name in raw["Model"].text:
                name = possible_name
                break

        model = dict(
            lang=current_lang,
            name=name,
            url=raw["Model"].find("a").get("href"),
            description=raw["Notes"].decode_contents(),
            size=raw["Size"].text,
            type="transcription",
            download_type="http+zip",
        )
        models += [model]


def print_table_from_dict_list(dict_list, columns=None):
    from rich.console import Console
    from rich.table import Table

    table = Table()
    if columns is None:
        columns = set()
        for d in dict_list:
            columns |= set(d.keys())

    for c in columns:
        table.add_column(c)
    for d in dict_list:
        table.add_row(*[d.get(c, "") for c in columns])

    console = Console()
    console.print(table)


print_table_from_dict_list(models, columns=["lang", "name", "url"])

by_language = defaultdict(list)
names_by_language = defaultdict(set)
for model in models:
    lang = model["lang"]
    del model["lang"]

    i = 2
    name = model["name"]
    while name in names_by_language[lang]:
        name = model["name"] + "-" + str(i)
        i += 1
    model["name"] = name
    names_by_language[lang].add(name)

    by_language[lang] += [model]

with open(Path(__file__).parent.parent / "app" / "models.yml", "w") as outfile:
    outfile.write(
        "# this file is autogenerated by the "
        "../scripts/generate_models_list.py script.\n"
        "# do not edit manually!\n\n"
    )
    yaml.dump(dict(by_language), outfile, sort_keys=False)
